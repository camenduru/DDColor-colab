{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/DDColor-colab/blob/main/DDColor_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/DDColor\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/cv_ddcolor_image-colorization/resolve/main/pytorch_model.pt -d /content/DDColor/models -o pytorch_model.pt\n",
        "\n",
        "!wget https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/audrey_hepburn.jpg -O /content/DDColor/in.jpg\n",
        "!pip install -q timm\n",
        "\n",
        "%cd /content/DDColor\n",
        "\n",
        "!sed -i 's/from \\.version import __gitsha__, __version__/# from \\.version import __gitsha__, __version__/' /content/DDColor/basicsr/__init__.py\n",
        "\n",
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from basicsr.archs.ddcolor_arch import DDColor\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ImageColorizationPipeline(object):\n",
        "\n",
        "    def __init__(self, model_path, input_size=256, model_size='large'):\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = torch.device('cuda')\n",
        "        else:\n",
        "            self.device = torch.device('cpu')\n",
        "\n",
        "        if model_size == 'tiny':\n",
        "            self.encoder_name = 'convnext-t'\n",
        "        else:\n",
        "            self.encoder_name = 'convnext-l'\n",
        "\n",
        "        self.decoder_type = \"MultiScaleColorDecoder\"\n",
        "\n",
        "        if self.decoder_type == 'MultiScaleColorDecoder':\n",
        "            self.model = DDColor(\n",
        "                encoder_name=self.encoder_name,\n",
        "                decoder_name='MultiScaleColorDecoder',\n",
        "                input_size=[self.input_size, self.input_size],\n",
        "                num_output_channels=2,\n",
        "                last_norm='Spectral',\n",
        "                do_normalize=False,\n",
        "                num_queries=100,\n",
        "                num_scales=3,\n",
        "                dec_layers=9,\n",
        "            ).to(self.device)\n",
        "        else:\n",
        "            self.model = DDColor(\n",
        "                encoder_name=self.encoder_name,\n",
        "                decoder_name='SingleColorDecoder',\n",
        "                input_size=[self.input_size, self.input_size],\n",
        "                num_output_channels=2,\n",
        "                last_norm='Spectral',\n",
        "                do_normalize=False,\n",
        "                num_queries=256,\n",
        "            ).to(self.device)\n",
        "\n",
        "        self.model.load_state_dict(\n",
        "            torch.load(model_path, map_location=torch.device('cpu'))['params'],\n",
        "            strict=False)\n",
        "        self.model.eval()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def process(self, img):\n",
        "        self.height, self.width = img.shape[:2]\n",
        "        # print(self.width, self.height)\n",
        "        # if self.width * self.height < 100000:\n",
        "        #     self.input_size = 256\n",
        "\n",
        "        img = (img / 255.0).astype(np.float32)\n",
        "        orig_l = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:, :, :1]  # (h, w, 1)\n",
        "\n",
        "        # resize rgb image -> lab -> get grey -> rgb\n",
        "        img = cv2.resize(img, (self.input_size, self.input_size))\n",
        "        img_l = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:, :, :1]\n",
        "        img_gray_lab = np.concatenate((img_l, np.zeros_like(img_l), np.zeros_like(img_l)), axis=-1)\n",
        "        img_gray_rgb = cv2.cvtColor(img_gray_lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "        tensor_gray_rgb = torch.from_numpy(img_gray_rgb.transpose((2, 0, 1))).float().unsqueeze(0).to(self.device)\n",
        "        output_ab = self.model(tensor_gray_rgb).cpu()  # (1, 2, self.height, self.width)\n",
        "\n",
        "        # resize ab -> concat original l -> rgb\n",
        "        output_ab_resize = F.interpolate(output_ab, size=(self.height, self.width))[0].float().numpy().transpose(1, 2, 0)\n",
        "        output_lab = np.concatenate((orig_l, output_ab_resize), axis=-1)\n",
        "        output_bgr = cv2.cvtColor(output_lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        output_img = (output_bgr * 255.0).round().astype(np.uint8)    \n",
        "\n",
        "        return output_img\n",
        "\n",
        "colorizer = ImageColorizationPipeline(model_path='/content/DDColor/models/pytorch_model.pt', input_size=512)\n",
        "\n",
        "# helper function taken from: https://huggingface.co/blog/stable_diffusion\n",
        "from PIL import Image\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_in = cv2.imread('/content/DDColor/in.jpg')\n",
        "image_out = colorizer.process(image_in)\n",
        "cv2.imwrite('/content/DDColor/out.jpg', image_out)\n",
        "image_in_pil = Image.fromarray(cv2.cvtColor(image_in, cv2.COLOR_BGR2RGB))\n",
        "image_out_pil = Image.fromarray(cv2.cvtColor(image_out, cv2.COLOR_BGR2RGB))\n",
        "images = [image_in_pil, image_out_pil]\n",
        "grid = image_grid(images, rows=1, cols=2)\n",
        "grid"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
